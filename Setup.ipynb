{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "# Data manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before working on Dataset, I made dataset column names and some values consistant\n",
    "\n",
    "df = pd.read_csv('Datasets\\\\Stroke_Dataset.csv')\n",
    "\n",
    "def rename_columns(df):\n",
    "    column_mapping = {\n",
    "        \"id\": \"Patient_ID\",\n",
    "        \"gender\": \"Gender\",\n",
    "        \"age\": \"Age\",\n",
    "        \"hypertension\": \"Hypertension\",\n",
    "        \"heart_disease\": \"Heart_Disease\",\n",
    "        \"ever_married\": \"Ever_Married\",\n",
    "        \"work_type\": \"Work_Type\",\n",
    "        \"Residence_type\": \"Residence_Type\",\n",
    "        \"avg_glucose_level\": \"Avg_Glucose_Level\",\n",
    "        \"bmi\": \"BMI\",\n",
    "        \"smoking_status\": \"Smoking_Status\",\n",
    "        \"stroke\": \"Stroke\"\n",
    "    }\n",
    "    \n",
    "    df = df.rename(columns=column_mapping)\n",
    "    return df\n",
    "\n",
    "def replace_binary_values(df, column):\n",
    "    df[column] = df[column].replace({1: \"Yes\", 0: \"No\"})\n",
    "    return df\n",
    "\n",
    "df = rename_columns(df)  # Rename columns\n",
    "\n",
    "df = replace_binary_values(df, \"Hypertension\")\n",
    "df = replace_binary_values(df, \"Heart_Disease\")\n",
    "df = replace_binary_values(df, \"Stroke\")\n",
    "\n",
    "df['Smoking_Status'] = df['Smoking_Status'].replace({\n",
    "    'formerly smoked': 'Formerly Smoked',\n",
    "    'never smoked': 'Never Smoked',\n",
    "    'smokes': 'Smokes'\n",
    "    })\n",
    "\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "\n",
    "# Save as a Parquet file\n",
    "df.to_parquet(\"Datasets\\\\Stroke_Dataset.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads Dataset and shows it's basic structure, (also handles any errors)\n",
    "def Load_Dataset(filePath):\n",
    "    try:\n",
    "        df = pd.read_parquet(filePath)\n",
    "        print(f\"Dataset loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "        print(\"DataFrame Shape: \", df.shape)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filePath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list(list):\n",
    "    # Convert the list to a DataFrame and transpose it for a horizontal display\n",
    "    df_summary = pd.DataFrame([list], columns=[f\"{i+1}\" for i in range(len(list))])\n",
    "    \n",
    "    # Display the DataFrame in a horizontal format\n",
    "    display(df_summary.style.set_properties(**{'text-align': 'center'}).set_table_styles(\n",
    "        [{'selector': 'th', 'props': [('text-align', 'center')]}]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_info(dataframe):\n",
    "    # Create a DataFrame and displays it horizontaly\n",
    "    df_summary = pd.DataFrame(\n",
    "        {col: [str(dataframe[col].dtype), dataframe[col].notnull().sum()] for col in dataframe.columns},\n",
    "        index=[\"Data_type\", \"Non_Null\"]\n",
    "    )\n",
    "    \n",
    "    # Display as a well-formatted table\n",
    "    display(df_summary.style.set_properties(**{'text-align': 'center'}).set_table_styles(\n",
    "        [{'selector': 'th', 'props': [('text-align', 'center')]}]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows information of dataset in a well formatted table\n",
    "\n",
    "def df_unique_counts(dataframe):\n",
    "    df_summary = pd.DataFrame(dataframe.nunique()).T  # This make df columns as columns\n",
    "    display(df_summary.style.set_properties(**{'text-align': 'center'}).set_table_styles(\n",
    "        [{'selector': 'th', 'props': [('text-align', 'center')]}]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display feature importances as a well-formatted table (I'll print it after plot)\n",
    "def df_feature_importances(dataframe):\n",
    "    df_summary = dataframe.T\n",
    "    display(df_summary.style.set_properties(**{'text-align': 'left'}).set_table_styles(\n",
    "        [{'selector': 'th', 'props': [('text-align', 'left')]}]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model metrics in table\n",
    "def display_metrics(metrics, model_name=\"Model\"):\n",
    "    \n",
    "    \n",
    "    # Create Matrics\n",
    "    df_metrics = pd.DataFrame({metric: [value] for metric, value in metrics.items()})\n",
    "    \n",
    "    # A row index\n",
    "    df_metrics.index = [' ']\n",
    "    \n",
    "    # Format all values to decimal places\n",
    "    for col in df_metrics.columns:\n",
    "        df_metrics[col] = df_metrics[col].apply(lambda x: f\"{x:.2f}\")\n",
    "    \n",
    "    # Apply minimal styling\n",
    "    styled_df = df_metrics.style.set_caption(f\"{model_name} Performance Metrics\").set_properties(**{\n",
    "        'text-align': 'center'\n",
    "    })\n",
    "    \n",
    "    display(styled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply style to all plots\n",
    "\n",
    "##### Included some general styles and settings, (I'll be using this in all of my plots for consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(fig_size=(10, 6)):\n",
    "\n",
    "    plt.style.use('petroff10')\n",
    "\n",
    "    # Color Palette\n",
    "    color_palette  = [\n",
    "    \"#cdb4db\",\n",
    "    \"#ffc8dd\",\n",
    "    \"#ffafcc\",\n",
    "    \"#bde0fe\",\n",
    "    \"#a2d2ff\",\n",
    "    \"#fbc3bc\",\n",
    "    \"#d4a5a5\",  \n",
    "    \"#9cadce\",  \n",
    "    \"#99c1b9\",  \n",
    "    \"#f7d6e0\"   \n",
    "]\n",
    "\n",
    "    # Apply globally\n",
    "    plt.rcParams['axes.prop_cycle'] = plt.cycler(color=color_palette)\n",
    "\n",
    "    light_bg = '#ffffff'\n",
    "    light_panel = '#f7f7f7'\n",
    "\n",
    "    # Configure figure properties\n",
    "    plt.rcParams['figure.facecolor'] = light_bg\n",
    "    plt.rcParams['figure.figsize'] = fig_size\n",
    "    plt.rcParams['figure.dpi'] = 120\n",
    "\n",
    "    # Configure axes properties\n",
    "    plt.rcParams['axes.facecolor'] = light_bg\n",
    "    plt.rcParams['axes.edgecolor'] = '#cccccc'\n",
    "    plt.rcParams['axes.labelcolor'] = '#333333'\n",
    "    plt.rcParams['axes.axisbelow'] = True\n",
    "    plt.rcParams['axes.grid'] = True\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "\n",
    "    # Remove top and right spines so that, it looks cleaner\n",
    "    plt.rcParams['axes.spines.top'] = False\n",
    "    plt.rcParams['axes.spines.right'] = False\n",
    "\n",
    "    # Configure grid \n",
    "    plt.rcParams['grid.color'] = '#e0e0e0'\n",
    "    plt.rcParams['grid.alpha'] = 0.5\n",
    "    plt.rcParams['grid.linestyle'] = '--'\n",
    "\n",
    "    # tick properties\n",
    "    plt.rcParams['xtick.color'] = '#555555'\n",
    "    plt.rcParams['ytick.color'] = '#555555'\n",
    "    plt.rcParams['xtick.labelsize'] = 10\n",
    "    plt.rcParams['ytick.labelsize'] = 10\n",
    "\n",
    "    # overall font settings\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['axes.titlesize'] = 16\n",
    "    plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "    # Configure legend\n",
    "    plt.rcParams['legend.facecolor'] = light_panel\n",
    "    plt.rcParams['legend.edgecolor'] = '#dddddd'\n",
    "    plt.rcParams['legend.fontsize'] = 10\n",
    "    plt.rcParams['legend.framealpha'] = 0.8\n",
    "\n",
    "    # seaborn style t(needed for matplotlib settings)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"notebook\", font_scale=1)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've created a single function to create subplots for bar & pie..\n",
    "\n",
    "def generate_subplots(plot, df, column_list, columns=3, fig_size=(18, 5)):\n",
    "    if plot in ['bar', 'pie']:\n",
    "\n",
    "        visualization(fig_size)  # Applies global color cycle\n",
    "\n",
    "        n_features = len(column_list)\n",
    "        n_cols = columns\n",
    "        n_rows = math.ceil(n_features / n_cols)\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(fig_size[0], fig_size[1] * n_rows))\n",
    "        \n",
    "        # Handle the case where there's only one subplot\n",
    "        if n_features == 1 and n_rows == 1 and n_cols == 1:\n",
    "            axes = np.array([axes])\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "\n",
    "        if plot == 'bar':\n",
    "            for i, feature in enumerate(column_list):\n",
    "                ax = axes[i]\n",
    "                value_counts = df[feature].value_counts()\n",
    "\n",
    "                # Get colors from the Matplotlib color cycle\n",
    "                colors = plt.cm.get_cmap('tab10', len(value_counts)).colors\n",
    "\n",
    "                ax.bar(value_counts.index, value_counts.values, color=colors)\n",
    "                ax.set_title(f'Distribution of {feature}', fontsize=12)\n",
    "                ax.set_xlabel(feature)\n",
    "                ax.set_ylabel('Count')\n",
    "\n",
    "                for j, val in enumerate(value_counts.values):\n",
    "                    ax.text(j, val, str(val), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "        elif plot == 'pie':\n",
    "            for i, feature in enumerate(column_list):\n",
    "                ax = axes[i]\n",
    "                value_counts = df[feature].value_counts()\n",
    "\n",
    "                labels = [f'{val} ({count})' for val, count in zip(value_counts.index, value_counts.values)]\n",
    "                colors = plt.cm.get_cmap('tab10', len(value_counts)).colors\n",
    "\n",
    "                ax.pie(value_counts, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "                ax.set_title(f'Distribution of {feature}', fontsize=12)\n",
    "                ax.legend(labels, loc='upper center', bbox_to_anchor=(0.9, 1.0), ncol=1, fontsize='small')\n",
    "\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "        plt.tight_layout(pad=3.0)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Invalid Argument:\", plot)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a simple function, (to avoid repetitive code)\n",
    "\n",
    "def gen_dist_plot_grp(dataframe, feature, bins=30, kde=True):\n",
    "\n",
    "    # I used subplot2grid to place each plot as I wanted\n",
    "\n",
    "    # Histogram Plot\n",
    "    ax1 = plt.subplot2grid((3, 2), (0, 0), colspan=2, rowspan=2)\n",
    "    sns.histplot(dataframe[feature], bins=bins, kde=kde, ax=ax1)\n",
    "    ax1.set_title(f'Histogram of {feature}')\n",
    "    ax1.set_xlabel(feature)\n",
    "    ax1.set_ylabel('Count')\n",
    "\n",
    "    # Box Plot\n",
    "    ax2 = plt.subplot2grid((3, 2), (2, 0))\n",
    "    sns.boxplot(x=dataframe[feature], ax=ax2)\n",
    "    ax2.set_title(f'Box Plot of {feature}')\n",
    "    ax2.set_xlabel(feature)\n",
    "\n",
    "    # Violin Plot\n",
    "    ax3 = plt.subplot2grid((3, 2), (2, 1))\n",
    "    sns.violinplot(x=dataframe[feature], ax=ax3)\n",
    "    ax3.set_title(f'Violin Plot of {feature}')\n",
    "    ax3.set_xlabel(feature)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Performance Analysis Plot Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(y_test, model_results_dict):\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot diagonal line (random classifier)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    \n",
    "    # Plot ROC curve for each model\n",
    "    for model_name, results in model_results_dict.items():\n",
    "        probabilities = results['probabilities']\n",
    "        \n",
    "        # Calculate ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, probabilities)\n",
    "        roc_auc = results['metrics']['ROC_AUC']\n",
    "        \n",
    "        # Plot the ROC curve\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.4f})')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('ROC Curves Comparison', fontsize=14)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_curves(y_test, model_results_dict):\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot PR curve for each model\n",
    "    for model_name, results in model_results_dict.items():\n",
    "        probabilities = results['probabilities']\n",
    "        \n",
    "        # Calculate Precision-Recall curve\n",
    "        precision, recall, _ = precision_recall_curve(y_test, probabilities)\n",
    "        pr_auc = results['metrics']['PR_AUC']\n",
    "        \n",
    "        # Plot the PR curve\n",
    "        plt.plot(recall, precision, lw=2, label=f'{model_name} (PR AUC = {pr_auc:.4f})')\n",
    "    \n",
    "    # Plot baseline\n",
    "    no_skill = sum(y_test) / len(y_test)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], 'k--', lw=2, label=f'Baseline ({no_skill:.4f})')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall', fontsize=12)\n",
    "    plt.ylabel('Precision', fontsize=12)\n",
    "    plt.title('Precision-Recall Curves Comparison', fontsize=14)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_comparison(model_results_dict, metrics_to_plot=None):\n",
    "\n",
    "    if metrics_to_plot is None:\n",
    "        metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC_AUC']\n",
    "    \n",
    "    # Extract metrics from each model\n",
    "    data = {}\n",
    "    for model_name, results in model_results_dict.items():\n",
    "        model_metrics = results['metrics']\n",
    "        data[model_name] = [model_metrics[metric] for metric in metrics_to_plot]\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Set width of bars\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(metrics_to_plot))\n",
    "    \n",
    "    # Plot bars for each model\n",
    "    for i, (model_name, values) in enumerate(data.items()):\n",
    "        ax.bar(index + i * bar_width, values, bar_width, label=model_name)\n",
    "    \n",
    "    # Add labels and customize plot\n",
    "    ax.set_xlabel('Metrics', fontsize=12)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title('Model Performance Comparison', fontsize=14)\n",
    "    ax.set_xticks(index + bar_width * (len(data) - 1) / 2)\n",
    "    ax.set_xticklabels(metrics_to_plot)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for i, rect in enumerate(ax.patches):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., height + 0.01,\n",
    "                f'{height:.2f}', ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.ylim(0, 1.1)  # Metrics are typically between 0 and 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(model_results_dict, class_names=None):\n",
    "    \n",
    "    if class_names is None:\n",
    "        class_names = ['Negative', 'Positive']\n",
    "    \n",
    "    # Calculate number of rows and columns for subplots\n",
    "    n_models = len(model_results_dict)\n",
    "    n_cols = min(2, n_models)\n",
    "    n_rows = (n_models + n_cols - 1) // n_cols\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*6, n_rows*5))\n",
    "    \n",
    "    # Make axes a 2D array even if there's only one row\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Flatten axes for easy iteration if there's only one model\n",
    "    if n_models == 1:\n",
    "        axes = np.array([axes])\n",
    "    \n",
    "    # Plot each confusion matrix\n",
    "    for i, (model_name, results) in enumerate(model_results_dict.items()):\n",
    "        row = i // n_cols\n",
    "        col = i % n_cols\n",
    "        \n",
    "        cm = results['confusion_matrix']\n",
    "        \n",
    "        # Normalize confusion matrix\n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # use thin in next line if you want to see normalized ones..\n",
    "        \n",
    "        # Plot\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=class_names, yticklabels=class_names, ax=axes[row, col])\n",
    "        \n",
    "        # Add labels and title\n",
    "        axes[row, col].set_xlabel('Predicted Label')\n",
    "        axes[row, col].set_ylabel('True Label')\n",
    "        axes[row, col].set_title(f'{model_name}\\nConfusion Matrix')\n",
    "        \n",
    "        # Calculate and display accuracy\n",
    "        accuracy = results['metrics']['Accuracy']\n",
    "        axes[row, col].text(0.12, 1.02, f'Accuracy: {accuracy:.4f}', \n",
    "                         ha='center', va='center', transform=axes[row, col].transAxes)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_models, n_rows * n_cols):\n",
    "        row = i // n_cols\n",
    "        col = i % n_cols\n",
    "        fig.delaxes(axes[row, col])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
